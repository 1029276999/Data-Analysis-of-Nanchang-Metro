{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取空气质量数据爬虫\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy\n",
    "import csv\n",
    "import time\n",
    "\n",
    "#数值单位：μg/m3(CO为mg/m3)\n",
    "\n",
    "def GetWeather(url):\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"lxml\", from_encoding=\"gb18030\")\n",
    "    tablelist = soup.findAll(\"tr\")\n",
    "    dataset = []\n",
    "    for datalist in tablelist[1:]:\n",
    "        data = datalist.get_text().replace(\" \", \"\").replace(\"\\r\\n\", \"\").strip(\"\\n\").split(\"\\n\")\n",
    "        dataset.append(data)\n",
    "    return dataset\n",
    "\n",
    "def Getweatherhead(url):\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, \"lxml\", from_encoding=\"gb18030\")  \n",
    " \n",
    "    tablelist = soup.findAll(\"tr\")  \n",
    "    Dataset = []\n",
    "    tablehead = tablelist[0].get_text().strip(\"\\n\").split(\"\\n\\n\")\n",
    "    Dataset.append(tablehead) \n",
    " \n",
    "    dataset = []\n",
    "    for datalist in tablelist[1:]:\n",
    "        data = datalist.get_text().replace(\" \", \"\").replace(\"\\r\\n\", \"\").strip(\"\\n\").split(\"\\n\")\n",
    "        dataset.append(data) \n",
    "    Dataset = numpy.row_stack((Dataset, dataset))\n",
    "    return Dataset\n",
    "\n",
    " \n",
    "start =time.clock()\n",
    "city=\"nanchang\"\n",
    "starturl = \"http://www.tianqihoubao.com/aqi/\"+city+\".html\"\n",
    "soup = BeautifulSoup(urlopen(starturl), \"lxml\")  \n",
    "\n",
    "Sites = []\n",
    "for i in soup.findAll(href=re.compile(\"^(/aqi/nanchang-)\")):\n",
    "    site = \"http://www.tianqihoubao.com\" + i.attrs['href']\n",
    "    Sites.append(site)\n",
    "\n",
    "Sites.reverse()\n",
    "\n",
    "Dataset = Getweatherhead(Sites[0]) \n",
    "for url in Sites[1:]:\n",
    "    dataset = GetWeather(url)\n",
    "    Dataset = numpy.row_stack((Dataset, dataset))  \n",
    "    weatherfile = open(\"nanchang.csv\", \"w\")  \n",
    "try:\n",
    "    writer = csv.writer(weatherfile)\n",
    "    for i in range(numpy.shape(Dataset)[0]):\n",
    "        writer.writerow((Dataset[i, :]))  \n",
    "finally:\n",
    "    weatherfile.close()  \n",
    "    end = time.clock()\n",
    "    print('Running time: %s Seconds' % (end - start))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
